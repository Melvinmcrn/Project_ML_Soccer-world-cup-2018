{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Soccer World Cup 2018 Winner Prediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Melvinmcrn/Project_ML_Soccer-world-cup-2018/blob/master/Soccer%20World%20Cup%202018%20Winner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGddoPsREarD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sb\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R73HvR-UH5w-",
        "colab_type": "text"
      },
      "source": [
        "# **Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW4w4JuSNBxT",
        "colab_type": "text"
      },
      "source": [
        "there are 3 datasets here.<br>\n",
        "1. **rankings**: FIFA ranking and points for the teams, which is a monthly changing rank previously shown as a decent predictor of team performance<br>\n",
        "2. **matches**: used to find out how much the difference in point, ranks and the current rank of the team affects the outocme of a match<br>\n",
        "3. **world_cup**: upcoming matches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCH2_UFpH9eV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rankings = pd.read_csv('https://raw.githubusercontent.com/Melvinmcrn/Project_ML_Soccer-world-cup-2018/master/data/fifa_ranking.csv')\n",
        "matches = pd.read_csv('https://raw.githubusercontent.com/Melvinmcrn/Project_ML_Soccer-world-cup-2018/master/data/results.csv')\n",
        "world_cup = pd.read_csv('https://raw.githubusercontent.com/Melvinmcrn/Project_ML_Soccer-world-cup-2018/master/data/World%20Cup%202018%20Dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCo3TIDrN2vX",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare 'rankings'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25Fnz2bAL_jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rankings.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3bo0S_HN6Oe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rankings = rankings.loc[:,['rank', 'country_full', 'country_abrv', 'cur_year_avg_weighted', 'rank_date', 'two_year_ago_weighted', 'three_year_ago_weighted']]\n",
        "rankings = rankings.replace({\"IR Iran\": \"Iran\"})\n",
        "rankings['weighted_points'] =  rankings['cur_year_avg_weighted'] + rankings['two_year_ago_weighted'] + rankings['three_year_ago_weighted']\n",
        "rankings['rank_date'] = pd.to_datetime(rankings['rank_date'])\n",
        "rankings.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVvZl3mJOsOh",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare 'matches'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSjmDBjvOoB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matches.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiehkDWPOwO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matches =  matches.replace({'Germany DR': 'Germany', 'China': 'China PR'})\n",
        "matches['date'] = pd.to_datetime(matches['date'])\n",
        "matches.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eha4QVYmO3Fx",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare 'world_cup'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anMIHNDPO-eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "world_cup.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDRinUjKO1in",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "world_cup = world_cup.loc[:, ['Team', 'Group', 'First match \\nagainst', 'Second match\\n against', 'Third match\\n against']]\n",
        "world_cup = world_cup.dropna(how='all')\n",
        "world_cup = world_cup.replace({\"IRAN\": \"Iran\", \n",
        "                               \"Costarica\": \"Costa Rica\", \n",
        "                               \"Porugal\": \"Portugal\", \n",
        "                               \"Columbia\": \"Colombia\", \n",
        "                               \"Korea\" : \"Korea Republic\"})\n",
        "world_cup = world_cup.set_index('Team')\n",
        "world_cup.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w_i3hPfiPhSW"
      },
      "source": [
        "# **Feature extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j149XRu-PmU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I want to have the ranks for every day \n",
        "rankings = rankings.set_index(['rank_date'])\\\n",
        "            .groupby(['country_full'], group_keys=False)\\\n",
        "            .resample('D').first()\\\n",
        "            .fillna(method='ffill')\\\n",
        "            .reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XzQOoksQBCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rankings.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykLMKFKHP7AA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# join the ranks\n",
        "matches_rank = matches.merge(rankings, \n",
        "                        left_on=['date', 'home_team'], \n",
        "                        right_on=['rank_date', 'country_full'])\n",
        "matches_rank.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxmlEs0-QPQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matches_rank = matches_rank.merge(rankings, \n",
        "                        left_on=['date', 'away_team'], \n",
        "                        right_on=['rank_date', 'country_full'], \n",
        "                        suffixes=('_home', '_away'))\n",
        "matches_rank.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRuacfPDQRQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature generation\n",
        "matches_rank['rank_difference'] = matches_rank['rank_home'] - matches_rank['rank_away']\n",
        "matches_rank['average_rank'] = (matches_rank['rank_home'] + matches_rank['rank_away'])/2\n",
        "matches_rank['point_difference'] = matches_rank['weighted_points_home'] - matches_rank['weighted_points_away']\n",
        "matches_rank['score_difference'] = matches_rank['home_score'] - matches_rank['away_score']\n",
        "matches_rank['is_won'] = matches_rank['score_difference'] > 0 # take draw as lost\n",
        "matches_rank['is_stake'] = matches_rank['tournament'] != 'Friendly'\n",
        "matches_rank.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHIP8vxkTYgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I tried earlier rest days but it did not turn to be useful\n",
        "max_rest = 30\n",
        "matches_rank['rest_days'] = matches_rank.groupby('home_team').diff()['date'].dt.days.clip(0,max_rest).fillna(max_rest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV3lSl8ITiPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I tried earlier the team as well but that did not make a difference either\n",
        "matches_rank['wc_participant'] = matches_rank['home_team'] * matches_rank['home_team'].isin(world_cup.index.tolist())\n",
        "matches_rank['wc_participant'] = matches_rank['wc_participant'].replace({'':'Other'})\n",
        "matches_rank = matches_rank.join(pd.get_dummies(matches_rank['wc_participant']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CX2EwHfTq7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matches_rank.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-3mSkyXWKPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matches_rank.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fceQvFWMU2KY",
        "colab_type": "text"
      },
      "source": [
        "# **Visualize**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkP69y5lBDLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sb.set(style='darkgrid')\n",
        "sb.countplot(x='is_stake', data=matches_rank)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHk42JoiBJ_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sb.countplot(x='is_won', data=matches_rank)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUb0-ve8U6Dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,ax0 = plt.subplots(figsize=(20,5))\n",
        "sb.countplot(x='score_difference', data=matches_rank)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR0IfVuSBR7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find outlier\n",
        "fig,_ = plt.subplots(figsize=(10,5))\n",
        "sb.boxplot(x=matches_rank['score_difference'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWDz2vBLBZd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find outlier\n",
        "fig,_ = plt.subplots(figsize=(10,5))\n",
        "sb.boxplot(x=matches_rank['rank_difference'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIVelNDxhb28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove outlier\n",
        "matches_rank_clean = matches_rank[matches_rank['score_difference'] < 7]\n",
        "matches_rank_clean = matches_rank_clean[matches_rank_clean['score_difference'] > -6]\n",
        "\n",
        "fig,_ = plt.subplots(figsize=(10,5))\n",
        "sb.boxplot(x=matches_rank_clean['score_difference'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq0GODD_h19j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove outlier\n",
        "matches_rank_clean = matches_rank_clean[matches_rank_clean['rank_difference'] < 118]\n",
        "matches_rank_clean = matches_rank_clean[matches_rank_clean['rank_difference'] > -124]\n",
        "\n",
        "fig,_ = plt.subplots(figsize=(10,5))\n",
        "sb.boxplot(x=matches_rank_clean['rank_difference'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEXQhnoZT6cS",
        "colab_type": "text"
      },
      "source": [
        "# **Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPuLI7_yUKuU",
        "colab_type": "text"
      },
      "source": [
        "binary classifier (only predict 'win' or 'lost')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qawy2JQCBpg8",
        "colab_type": "text"
      },
      "source": [
        "## **Logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ8yNt-lBpK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoqFGnGuwBCj",
        "colab_type": "text"
      },
      "source": [
        "### evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXG6bpHiuyhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateModel(model, X_train, X_test, y_train, y_test):\n",
        "  # figures \n",
        "  fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
        "  plt.figure(figsize=(15,5))\n",
        "  ax = plt.subplot(1,3,1)\n",
        "  ax.plot([0, 1], [0, 1], 'k--')\n",
        "  ax.plot(fpr, tpr)\n",
        "  ax.set_title('AUC score is {0:0.2}'.format(roc_auc_score(y_test, model.predict_proba(X_test)[:,1])))\n",
        "  ax.set_aspect(1)\n",
        "\n",
        "  ax = plt.subplot(1,3,2)\n",
        "  cm = confusion_matrix(y_test, model.predict(X_test))\n",
        "  ax.imshow(cm, cmap='Blues', clim = (0, cm.max())) \n",
        "\n",
        "  ax.set_xlabel('Predicted label')\n",
        "  ax.set_title('Performance on the Test set')\n",
        "\n",
        "  ax = plt.subplot(1,3,3)\n",
        "  cm = confusion_matrix(y_train, model.predict(X_train))\n",
        "  ax.imshow(cm, cmap='Blues', clim = (0, cm.max())) \n",
        "  ax.set_xlabel('Predicted label')\n",
        "  ax.set_title('Performance on the Training set')\n",
        "  pass\n",
        "\n",
        "  features = ['average_rank', 'rank_difference', 'point_difference']\n",
        "  wrongs = y_test != model.predict(X_test)\n",
        "\n",
        "  for feature in features:\n",
        "      plt.figure()\n",
        "      plt.title(feature)\n",
        "      X_test.loc[wrongs, feature].plot.kde()\n",
        "      X.loc[:, feature].plot.kde()\n",
        "      plt.legend(['wrongs', 'all'])\n",
        "      \n",
        "  print(\"Stakes distribution in the wrong predictions\")\n",
        "  print(X_test.loc[wrongs, 'is_stake'].value_counts() / wrongs.sum())\n",
        "  print(\"Stakes distribution overall\")\n",
        "  print(X['is_stake'].value_counts() / X.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciFa_EB2jHVX",
        "colab_type": "text"
      },
      "source": [
        "### normal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvL3Zkv4TsIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake']], matches_rank['is_won']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg = linear_model.LogisticRegression(C=1e-5)\n",
        "features = PolynomialFeatures(degree=2)\n",
        "model = Pipeline([\n",
        "    ('polynomial_features', features),\n",
        "    ('logistic_regression', logreg)\n",
        "])\n",
        "model = model.fit(X_train, y_train)\n",
        "\n",
        "evaluateModel(model, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgIXsJT6jKIo",
        "colab_type": "text"
      },
      "source": [
        "### cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmzM9hxgD9AF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank_clean.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake']], matches_rank_clean['is_won']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg = linear_model.LogisticRegression(C=1e-5)\n",
        "features = PolynomialFeatures(degree=2)\n",
        "model = Pipeline([\n",
        "    ('polynomial_features', features),\n",
        "    ('logistic_regression', logreg)\n",
        "])\n",
        "model = model.fit(X_train, y_train)\n",
        "\n",
        "evaluateModel(model, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KBG4mT0uc76",
        "colab_type": "text"
      },
      "source": [
        "### normal data but add 'rest_days' to feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DTyhiqllKTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake', 'rest_days']], matches_rank['is_won']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg = linear_model.LogisticRegression(C=1e-5)\n",
        "features = PolynomialFeatures(degree=2)\n",
        "model = Pipeline([\n",
        "    ('polynomial_features', features),\n",
        "    ('logistic_regression', logreg)\n",
        "])\n",
        "model = model.fit(X_train, y_train)\n",
        "\n",
        "evaluateModel(model, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyerEMqwlB6T",
        "colab_type": "text"
      },
      "source": [
        "### cleaned data but add 'rest_days' to feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIRr9UjPjuok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank_clean.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake', 'rest_days']], matches_rank_clean['is_won']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg = linear_model.LogisticRegression(C=1e-5)\n",
        "features = PolynomialFeatures(degree=2)\n",
        "model = Pipeline([\n",
        "    ('polynomial_features', features),\n",
        "    ('logistic_regression', logreg)\n",
        "])\n",
        "model = model.fit(X_train, y_train)\n",
        "\n",
        "evaluateModel(model, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "emdO0lSl4xwu"
      },
      "source": [
        "## **Logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yXdtttrJ4xxM",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q3QYifZw4xxb"
      },
      "source": [
        "### evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T3UQjZmH4xxh",
        "colab": {}
      },
      "source": [
        "def evaluateModel(model, X_train, X_test, y_train, y_test):\n",
        "  # figures \n",
        "  fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
        "  plt.figure(figsize=(15,5))\n",
        "  ax = plt.subplot(1,3,1)\n",
        "  ax.plot([0, 1], [0, 1], 'k--')\n",
        "  ax.plot(fpr, tpr)\n",
        "  ax.set_title('AUC score is {0:0.2}'.format(roc_auc_score(y_test, model.predict_proba(X_test)[:,1])))\n",
        "  ax.set_aspect(1)\n",
        "\n",
        "  ax = plt.subplot(1,3,2)\n",
        "  cm = confusion_matrix(y_test, model.predict(X_test))\n",
        "  ax.imshow(cm, cmap='Blues', clim = (0, cm.max())) \n",
        "\n",
        "  ax.set_xlabel('Predicted label')\n",
        "  ax.set_title('Performance on the Test set')\n",
        "\n",
        "  ax = plt.subplot(1,3,3)\n",
        "  cm = confusion_matrix(y_train, model.predict(X_train))\n",
        "  ax.imshow(cm, cmap='Blues', clim = (0, cm.max())) \n",
        "  ax.set_xlabel('Predicted label')\n",
        "  ax.set_title('Performance on the Training set')\n",
        "  pass\n",
        "\n",
        "  features = ['average_rank', 'rank_difference', 'point_difference']\n",
        "  wrongs = y_test != model.predict(X_test)\n",
        "\n",
        "  for feature in features:\n",
        "      plt.figure()\n",
        "      plt.title(feature)\n",
        "      X_test.loc[wrongs, feature].plot.kde()\n",
        "      X.loc[:, feature].plot.kde()\n",
        "      plt.legend(['wrongs', 'all'])\n",
        "      \n",
        "  print(\"Stakes distribution in the wrong predictions\")\n",
        "  print(X_test.loc[wrongs, 'is_stake'].value_counts() / wrongs.sum())\n",
        "  print(\"Stakes distribution overall\")\n",
        "  print(X['is_stake'].value_counts() / X.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tSlRTc_x4xxp"
      },
      "source": [
        "### normal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "odtSXqAC4xxr",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake']], matches_rank['is_won']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg = linear_model.LogisticRegression(C=1e-5)\n",
        "features = PolynomialFeatures(degree=2)\n",
        "model = Pipeline([\n",
        "    ('polynomial_features', features),\n",
        "    ('logistic_regression', logreg)\n",
        "])\n",
        "model = model.fit(X_train, y_train)\n",
        "\n",
        "evaluateModel(model, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s4Pkeedl4xx7"
      },
      "source": [
        "### cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-S6TbuOg4xx-",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank_clean.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake']], matches_rank_clean['is_won']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg = linear_model.LogisticRegression(C=1e-5)\n",
        "features = PolynomialFeatures(degree=2)\n",
        "model = Pipeline([\n",
        "    ('polynomial_features', features),\n",
        "    ('logistic_regression', logreg)\n",
        "])\n",
        "model = model.fit(X_train, y_train)\n",
        "\n",
        "evaluateModel(model, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QXwM9GL-4xyG"
      },
      "source": [
        "### normal data but add 'rest_days' to feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gFlVW0kk4xyJ",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake', 'rest_days']], matches_rank['is_won']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg = linear_model.LogisticRegression(C=1e-5)\n",
        "features = PolynomialFeatures(degree=2)\n",
        "model = Pipeline([\n",
        "    ('polynomial_features', features),\n",
        "    ('logistic_regression', logreg)\n",
        "])\n",
        "model = model.fit(X_train, y_train)\n",
        "\n",
        "evaluateModel(model, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aUBsbR2P4xyR"
      },
      "source": [
        "### cleaned data but add 'rest_days' to feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jre2TqkV4xyT",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank_clean.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake', 'rest_days']], matches_rank_clean['is_won']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg = linear_model.LogisticRegression(C=1e-5)\n",
        "features = PolynomialFeatures(degree=2)\n",
        "model = Pipeline([\n",
        "    ('polynomial_features', features),\n",
        "    ('logistic_regression', logreg)\n",
        "])\n",
        "model = model.fit(X_train, y_train)\n",
        "\n",
        "evaluateModel(model, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v65-F3jm42qz"
      },
      "source": [
        "## **Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ud7r5IA342q3",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score,classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5ViBPK15FyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DecisionTree(X, y):\n",
        "  scale = StandardScaler()\n",
        "  X = scale.fit_transform(X)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "  test_size=0.2, random_state=42)\n",
        "\n",
        "  param_grid = {'max_depth': np.arange(1, 20),\n",
        " 'criterion':['entropy','gini']}\n",
        "  tree = GridSearchCV(DecisionTreeClassifier(), param_grid)\n",
        "  tree.fit(X_train, y_train)\n",
        "  print(tree.best_estimator_)\n",
        "\n",
        "  y_pred = tree.predict(X_test)\n",
        "\n",
        "  print(accuracy_score(y_test, y_pred))\n",
        "  print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UfjeDM5j42rL"
      },
      "source": [
        "### normal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QmKb_Cf442rN",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake']], matches_rank['is_won']\n",
        "DecisionTree(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y53oome542rY"
      },
      "source": [
        "### cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Epw2CD5I42ra",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank_clean.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake']], matches_rank_clean['is_won']\n",
        "DecisionTree(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1ajEpH2042rj"
      },
      "source": [
        "### normal data with feature 'rest_days'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FeC1Mzfi42rm",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake','rest_days']], matches_rank['is_won']\n",
        "DecisionTree(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vpZbj_5U42ru"
      },
      "source": [
        "### cleaned data with feature 'rest_days'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tlluqZt042rw",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank_clean.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake','rest_days']], matches_rank_clean['is_won']\n",
        "DecisionTree(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "smQ6TTCR6Vy7"
      },
      "source": [
        "## **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4AIsdMiv6VzG",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import svm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u1H6ZN_U6VzR",
        "colab": {}
      },
      "source": [
        "def SVM(X, y):\n",
        "  scale = StandardScaler()\n",
        "  X = scale.fit_transform(X)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "  test_size=0.2, random_state=42)\n",
        "\n",
        "  parameters = { 'C':np.arange(1,11,0.5), 'gamma':['auto','scale']}\n",
        "  svc = svm.SVC()\n",
        "  SVM=GridSearchCV(svc, parameters)\n",
        "  SVM.fit(X_train,y_train)\n",
        "  print(SVM.best_estimator_)\n",
        "\n",
        "  y_pred = SVM.predict(X_test)\n",
        "\n",
        "  print(accuracy_score(y_test, y_pred))\n",
        "  print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rfpCwD2P6Vzc"
      },
      "source": [
        "### normal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mSR-82KD6Vze",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake']], matches_rank['is_won']\n",
        "SVM(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yJXG4Ljm6Vzn"
      },
      "source": [
        "### cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QGNtJRvh6Vzp",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank_clean.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake']], matches_rank_clean['is_won']\n",
        "SVM(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vyEMwFW36Vzw"
      },
      "source": [
        "### normal data with feature 'rest_days'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dKaGee9T6Vzy",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake','rest_days']], matches_rank['is_won']\n",
        "SVM(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4POTaUaC6Vz5"
      },
      "source": [
        "### cleaned data with feature 'rest_days'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MjmZ_PsC6Vz7",
        "colab": {}
      },
      "source": [
        "X, y = matches_rank_clean.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake','rest_days']], matches_rank_clean['is_won']\n",
        "SVM(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faeVlO0Ww02p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}